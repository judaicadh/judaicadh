<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.9.2">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2022-05-02T10:05:15-04:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Judaica DH at the Penn Libraries</title><subtitle>Judaica Digital Humanities at the Penn Libraries is a robust program using digital technologies to augment and transform the ways in which to explore Jewish history. By experimenting with platforms, tools, and methodologies, we deepen and broaden our understanding of Jewish history, texts, cultures, ideas, and experiences.</subtitle><entry><title type="html">RECAP: Exploring Colenda Data with Jupyter Notebooks</title><link href="http://localhost:4000/blog/penn-presents/" rel="alternate" type="text/html" title="RECAP: Exploring Colenda Data with Jupyter Notebooks" /><published>2021-12-21T00:00:00-05:00</published><updated>2021-12-21T00:00:00-05:00</updated><id>http://localhost:4000/blog/penn-presents</id><content type="html" xml:base="http://localhost:4000/blog/penn-presents/"><![CDATA[# Video

<iframe id="kaltura_player" src="https://cdnapisec.kaltura.com/p/1147242/sp/114724200/embedIframeJs/uiconf_id/9757771/partner_id/1147242?iframeembed=true&playerId=kaltura_player&entry_id=1_t8522280&flashvars[streamerType]=auto&amp;flashvars[localizationCode]=en&amp;flashvars[leadWithHTML5]=true&amp;flashvars[sideBarContainer.plugin]=true&amp;flashvars[sideBarContainer.position]=left&amp;flashvars[sideBarContainer.clickToClose]=true&amp;flashvars[chapters.plugin]=true&amp;flashvars[chapters.layout]=vertical&amp;flashvars[chapters.thumbnailRotator]=false&amp;flashvars[streamSelector.plugin]=true&amp;flashvars[EmbedPlayer.SpinnerTarget]=videoHolder&amp;flashvars[dualScreen.plugin]=true&amp;flashvars[Kaltura.addCrossoriginToIframe]=true&amp;&wid=1_juqoo8j4" width="400" height="285" allowfullscreen webkitallowfullscreen mozAllowFullScreen allow="autoplay *; fullscreen *; encrypted-media *" sandbox="allow-forms allow-same-origin allow-scripts allow-top-navigation allow-pointer-lock allow-popups allow-modals allow-orientation-lock allow-popups-to-escape-sandbox allow-presentation allow-top-navigation-by-user-activation" frameborder="0" title="Kaltura Player"></iframe>


# Counts Over Time
{% include counts_over_time.html %}

# States Over Time
{% include states_over_time.html %}

# Types Over Time
{% include types_over_time.html %}

# World Chart
{% include world_chart.html %}]]></content><author><name>admin</name></author><summary type="html"><![CDATA[Video]]></summary></entry><entry><title type="html">RECAP: Crowdsourcing and the Humanities: Roundtable Discussions Celebrating Scribes of the Cairo Geniza</title><link href="http://localhost:4000/blog/2021-05-31-scribes-recap/" rel="alternate" type="text/html" title="RECAP: Crowdsourcing and the Humanities: Roundtable Discussions Celebrating Scribes of the Cairo Geniza" /><published>2021-05-31T00:00:00-04:00</published><updated>2021-05-31T00:00:00-04:00</updated><id>http://localhost:4000/blog/2021-05-31-scribes-recap</id><content type="html" xml:base="http://localhost:4000/blog/2021-05-31-scribes-recap/"><![CDATA[The Center for Research Data and Digital Scholarship at University of Pennsylvania Libraries, The Center for Digital Humanities at Princeton University Library, the Princeton Geniza Lab, and the Zooniverse present a series of conversations on project management and development, creation and use of data, and crowdsourcing platforms and research possibilities.

[Scribes of the Cairo Geniza](https://www.scribesofthecairogeniza.org/) is a multilingual crowdsourcing project launched in 2017 to classify and transcribe manuscript fragments from a medieval Egyptian synagogue. An initiative led by the University of Pennsylvania Libraries and Zooniverse, the project harnesses the power of technology and people to decipher some of the most challenging fragments in the world.

Building on the project’s work, this series of roundtable discussions explore methods for project development and management, data curation and use, and crowdsourcing experiences in conversation with historians, developers, librarians, philologists, curators, DH practitioners, Geniza specialists, and community members around the world. We hope to engage the field at-large in a community-building exercise to reflect on our project and its connections to other crowdsourcing efforts.

This event was part of the 2020–21 “Collections as Data” series presented by the Center for Digital Humanities and Princeton University Library. Now in its third year, the series was dedicated to exploring how library, archive, and museum collections can be leveraged to support data-driven scholarship and discovery. This year’s focus is community, exploring how communities can engage with and form around data-based projects.

View the recordings for each of these roundtables below:
- [Crowdsourcing and the Humanities: Meeting the Scribes of the Cairo Geniza Project Team](http://www.kaltura.com/tiny/u0ieh)
- [Crowdsourcing and the Humanities: Who are the #GenizaScribes?](http://www.kaltura.com/tiny/wkzfw)
- [Crowdsourcing and the Humanities: Platforms for People-Powered Research](http://www.kaltura.com/tiny/lj9gm)
- [Crowdsourcing and the Humanities: From the Technical Side: Responding to Researcher Needs](http://www.kaltura.com/tiny/sgb7k)
- [Crowdsourcing and the Humanities: Working with Crowdsourced Textual Data](http://www.kaltura.com/tiny/ov87l)
- [Crowdsourcing and the Humanities: Across The Zooniverse: Science and Humanities](http://www.kaltura.com/tiny/yxsv7)]]></content><author><name>admin</name></author><category term="Scribes of the Cairo Geniza" /><category term="Scribes of the Cairo Geniza" /><summary type="html"><![CDATA[The Center for Research Data and Digital Scholarship at University of Pennsylvania Libraries, The Center for Digital Humanities at Princeton University Library, the Princeton Geniza Lab, and the Zooniverse present a series of conversations on project management and development, creation and use of data, and crowdsourcing platforms and research possibilities.]]></summary></entry><entry><title type="html">EVENT: Crowdsourcing and the Humanities: Roundtable Discussions Celebrating Scribes of the Cairo Geniza</title><link href="http://localhost:4000/blog/2021-04-21-celebrating-scribes/" rel="alternate" type="text/html" title="EVENT: Crowdsourcing and the Humanities: Roundtable Discussions Celebrating Scribes of the Cairo Geniza" /><published>2021-04-21T00:00:00-04:00</published><updated>2021-04-21T00:00:00-04:00</updated><id>http://localhost:4000/blog/2021-04-21-celebrating-scribes</id><content type="html" xml:base="http://localhost:4000/blog/2021-04-21-celebrating-scribes/"><![CDATA[The Center for Research Data and Digital Scholarship at University of Pennsylvania Libraries, The Center for Digital Humanities at Princeton University Library, the Princeton Geniza Lab, and the Zooniverse present a series of conversations on project management and development, creation and use of data, and crowdsourcing platforms and research possibilities.

[Scribes of the Cairo Geniza](https://www.scribesofthecairogeniza.org/) is a multilingual crowdsourcing project launched in 2017 to classify and transcribe manuscript fragments from a medieval Egyptian synagogue. An initiative led by the University of Pennsylvania Libraries and Zooniverse, the project harnesses the power of technology and people to decipher some of the most challenging fragments in the world.

Building on the project’s work, this series of roundtable discussions will explore methods for project development and management, data curation and use, and crowdsourcing experiences in conversation with historians, developers, librarians, philologists, curators, DH practitioners, Geniza specialists, and community members around the world. We hope to engage the field at-large in a community-building exercise to reflect on our project and its connections to other crowdsourcing efforts.

This event is part of the 2020–21 “Collections as Data” series presented by the Center for Digital Humanities and Princeton University Library. Now in its third year, the series is dedicated to exploring how library, archive, and museum collections can be leveraged to support data-driven scholarship and discovery. This year’s focus is community, exploring how communities can engage with and form around data-based projects.

The [event](https://genizalab.princeton.edu/crowdsourcing-and-the-humanities) runs for 3 days, from April 14th-16th, 10 AM – 1:30 PM EDT. In these conversations, you’ll hear :
- How Scribes of the Cairo Geniza grew from an idea to ongoing project, and what our researchers, developers and volunteers have learned along the way.
- Different crowdsourcing platforms and projects share their approaches to project planning, development, and outreach.
- And other Zooniverse projects teams, like [Anti-Slavery Manuscripts](https://www.antislaverymanuscripts.org/), [Galaxy Zoo](https://www.galaxyzoo.org/), and [Wildwatch Kenya](https://www.zooniverse.org/projects/sandiegozooglobal/wildwatch-kenya), talking about their experiences in people-powered research.

We are so excited to learn from each other, and we invite you to be a part of the conversation! You can register for one or all of the conversations at [https://genizalab.princeton.edu/crowdsourcing-and-the-humanities](https://genizalab.princeton.edu/crowdsourcing-and-the-humanities). Each conversation will be recorded and shared widely after the event.

As always, you can visit [scribesofthecairogeniza.org](scribesofthecairogeniza.org) and dive into one of our many workflows. Try your hand at sorting some fragments or transcribe away!

Thanks for your help,
The Scribes of the Cairo Geniza Team]]></content><author><name>admin</name></author><category term="Scribes of the Cairo Geniza" /><category term="Scribes of the Cairo Geniza" /><summary type="html"><![CDATA[The Center for Research Data and Digital Scholarship at University of Pennsylvania Libraries, The Center for Digital Humanities at Princeton University Library, the Princeton Geniza Lab, and the Zooniverse present a series of conversations on project management and development, creation and use of data, and crowdsourcing platforms and research possibilities.]]></summary></entry><entry><title type="html">Omeka Orientation: How to Use This Web Publishing Platform</title><link href="http://localhost:4000/blog/2020-08-27-omeka-orientation/" rel="alternate" type="text/html" title="Omeka Orientation: How to Use This Web Publishing Platform" /><published>2020-08-27T00:00:00-04:00</published><updated>2020-08-27T00:00:00-04:00</updated><id>http://localhost:4000/blog/2020-08-27-omeka-orientation</id><content type="html" xml:base="http://localhost:4000/blog/2020-08-27-omeka-orientation/"><![CDATA[*The following transcript and slides were the draft of a workshop for he New Student Orientation: The Penn Libraries Digital Showcase Back to School Workshops series in August 2020. You can view the video here (forthcoming).*

![Omeka Orientation](https://judaicadh.github.io/assets/post-media/2020-08-27/1.jpg)

Hi everyone! Thank you so much for taking time out of your Thursday to join me for [Omeka Orientation](https://libcal.library.upenn.edu/event/6788667). 

![Penn Libraries Showcase](https://judaicadh.github.io/assets/post-media/2020-08-27/2.jpg)

This is part of the [New Student Orientation: The Penn Libraries Digital Showcase](https://guides.library.upenn.edu/nso), a week of online programming to help you get your year started right! Tune in to a Q&A panel for insider tips and tricks about navigating the libraries; get a virtual introduction to the librarians who can help you find the tools and resources you need; and sign up for a back-to-school workshop to pick up new skills. You can view all the [Back to School Workshops](https://guides.library.upenn.edu/c.php?g=476340&p=7687915) in the corresponding LibGuide, and all of these sessions are being recorded for future use. 

![About Emily Esten](https://judaicadh.github.io/assets/post-media/2020-08-27/4.jpg)

Some background on me: I am the Judaica Digital Humanities Coordinator in the Center for Research Data and Digital Scholarship here in the libraries, which means I work between Special Collections and the Center on projects related to Jewish history and culture. I also assist students, instructors, and staff with using Wordpress and Omeka, which are web publishing platforms. During my time at Penn, I have built two Omeka sites and hosted several others, including [Digital Second Edition of Judaica Americana](https://singermanja2.exhibits.library.upenn.edu/) and [Penn Holy Land Digitized Image Collections](http://pennds.org/holyland/). 

Today, we’ll be using some of those websites I’ve assisted as well as others here at Penn throughout the workshop as an example of what we can do with Omeka. 


![What is Omeka?](https://judaicadh.github.io/assets/post-media/2020-08-27/5.jpg)

So, first up - what is Omeka? 

_Omeka_ is a Swahili word meaning “to display or layout wares; to speak out; to spread out; to unpack.” The team behind Omeka, which includes the Corporation for Digital Scholarship,  the Roy Rosenzweig Center for History and New Media, and George Mason University, chose this name because they believed it signified what their project would do. Omeka helps its users display digital content and unpack stories through publishing collections and exhibits for online communities. Since its launch in February 2008, Omeka has established itself as a leading open source web publishing platform for digital collections. It has been downloaded over 150,000 times, and supported thousands of websites developed by galleries, libraries, archives, museums, and scholars. 

![Key Features of Omeka](https://judaicadh.github.io/assets/post-media/2020-08-27/6.jpg)

What are some of the key features of Omeka?

*   **Omeka is free and open-source**. That means Omeka can be downloaded and the software used for free by anyone and for any purpose.
*   **Omeka is easy to use**. They boast about a five-minute setup process, and it really is that simple. It’s designed with non-IT specialists in mind, allowing scholars like yourself to focus on the content and interpretation of collections rather than programming.
*   **Omeka emphasizes metadata**. For context, metadata is data that describes other data, as in its origin, structure, or characteristics. When you add an item to Omeka, you may include basic information - a Title, a Description, a Source, a Date, etc. And then you can use those items to build your collections and exhibits. We’ll discuss that a little later on.
*   **Omeka has lots of plugins**, which are applications that help extend the functionality of your site. Some examples include bulk importing items to your website, uploading files from Dropbox or similar spaces, adding pages to your site, embedding PDF documents, and more. 

When should you use Omeka over other web publishing platforms?

*   **When your goal is cataloging and archiving**. You have items which contain information or files related to a broader collection. 
*   **When you have a lot of media**. If your project involves images, videos, websites, and texts that you want to link to or include, and you want to display detailed information about an item, Omeka is designed for that purpose. 
*   **When you want to include community-sourced content**. Plugins like Scripto and Contribution allow for community contributions to items. 
*   **When you want to emphasize storytelling**. Omeka is built around the concept of creating online collections of digitized materials and curating them for the web. It offers a simple way to organize your collection into an attractive and interactive narrative.

![What have people built with Omeka?](https://judaicadh.github.io/assets/post-media/2020-08-27/7.jpg)

So *what* can you do with Omeka?


![Create a Digital Archive](https://judaicadh.github.io/assets/post-media/2020-08-27/8.jpg)

**Create a digital archive like [Penn Libraries Holy Land Digital Image Collections](http://pennds.org/holyland/)**: The site hosts over 18,000 images about the Holy Land. Laura Newman Eckstein, who was a staff member at Penn and is currently a graduate student, worked on building this archive to complement an exhibit here at the libraries. 


![Build a Digital Exhibit](https://judaicadh.github.io/assets/post-media/2020-08-27/9.jpg)

**Build a digital exhibit like [Laboring Over History](https://laboringoverhistory.omeka.net/exhibits/show/loh/start)**: This site was built by a student at Northeastern University for her senior thesis. In this exhibit visitors take a close look at the ways that women have fought together to achieve equality in the workplace, focusing on Boston but including other monumental strikes and events.


![Collaborate to Tell a Story](https://judaicadh.github.io/assets/post-media/2020-08-27/10.jpg)

**Collaborate to tell a story like [Digital Exploration of the Ancient City of Ur](http://pennds.org/digital_ur/)**: This site was created as part of the “Digital Exploration of The Past: Archives, Databases, Maps, and Museums” course here at Penn in Fall 2018. NELC 320. Students worked to digitize a selection of excavation field notes, transcribing their content and mapping various plans of the site. 


![Create a Mapped Narrative](https://judaicadh.github.io/assets/post-media/2020-08-27/11.jpg)

**Create a mapped narrative like [Paris sous l’Occupation](http://pennds.org/melanieperon/)**: Similarly, a French history and culture course explored Paris during World War II by mapping places, memories, and oral histories. Their maps weave together texts, videos, and biographical data to explore the dark history of occupation through spatial dimensions.


![Crowdsource Your Research](https://judaicadh.github.io/assets/post-media/2020-08-27/12.jpg)

**Crowdsource your research like [Transform/Transcribe MHC](https://transcribe.mtholyoke.edu/)**: The Archives and Special Collections staff at Mount Holyoke College use Omeka to transcribe historic documents and collection records alongside members in order to facilitate research and excite learning in everyone. They use a plugin called Scripto to allow volunteers to transcribe these documents and help make Mount Holyoke’s collections in the history of women in higher education more accessible to anyone. 


![Createa Mobile Tour](https://judaicadh.github.io/assets/post-media/2020-08-27/13.jpg)

**Create a Mobile Tour like [DC Historic Sites](https://historicsites.dcpreservation.org/)**: DC Historic Sites uses Curatescape, a set of tools and plugins for Omeka, to curate tours of historic sites in the District of Columbia. Visitors can browse tours or sites to gain new insight about neighborhood histories. 


![What might that look like for me?](https://judaicadh.github.io/assets/post-media/2020-08-27/14.jpg)

The following slides come from my colleague Sasha Renninger in SAS Computing - I’ve changed them significantly but I do want to highlight her work. 


![Making an Omeka Exhibit](https://judaicadh.github.io/assets/post-media/2020-08-27/15.jpg)

Let’s say you wanted to build an Omeka exhibit about Art at the University of Pennsylvania, featuring outdoor art  in walking distance of the library. You could feature the LOVE sculpture, the Split Button, and Benjamin Franklin. (Fun fact: this is [an actual Omeka site](http://pennds.org/arth503640)!) 


![Parts of Omeka: Items and Files](https://judaicadh.github.io/assets/post-media/2020-08-27/16.jpg)

Each of these would be considered an “item” in Omeka, to which you could attach respective files. For LOVE, you might attach image files - one from winter and one from spring. For Split Button, you might have an image and then a text file about the history of the sculpture. And for Benjamin Franklin, you might have an image, a PDF about Franklin and the university, and maybe even an audio file talking about the sculpture on a walking tour.


![Parts of Omeka: Describing an Item with Metadata](https://judaicadh.github.io/assets/post-media/2020-08-27/17.jpg)

When you add an item to Omeka, you can also add metadata - all this descriptive information about your item. Omeka uses a metadata set called “Dublin Core” to provide basic information about your item, such as 
- Title
- Description (what am I looking at here? what is interesting about this?)
- Creator (who made this?)
- Source (if you aren't the creator, where did you get this?)
- Data
- Format (what is this made of? what are its physical dimensions?)
- Relation (where can I go for more information?)
- Coverage (where is this from? when is this from)>

You can also give specific Item Type Metadata for an image, and possibly create your own as a way to describe your item. Some possible item types include:
- Physical Object
- Image (Still Image)
- Sound
- Video (Moving Image)
- Website 
- Person 


![Building an Exhibit](https://judaicadh.github.io/assets/post-media/2020-08-27/18.jpg)

And then you can build your exhibit, combining your items and contextualizing them together on one page. [In this case](http://pennds.org/arth503640/items/show/24), the author talks about the other Benjamin Franklin artwork on campus.


![Next Steps](https://judaicadh.github.io/assets/post-media/2020-08-27/19.jpg)

I hope this has you excited about the possibilities of using Omeka for your projects! Penn Libraries supports Omeka as a digital platform, and the first place to look for more information is the Omeka LibGuide at [guides.library.upenn.edu/omeka](guides.library.upenn.edu/omeka).  It contains some of the projects I mentioned today, as well as additional resources for learning more. And you can always reach out to the Omeka support team by emailing [libds-support@o365lists.upenn.edu](mailto:libds-support@o365lists.upenn.edu) for assistance.]]></content><author><name>emily-esten</name></author><category term="Presentations" /><category term="Omeka" /><summary type="html"><![CDATA[The following transcript and slides were the draft of a workshop for he New Student Orientation: The Penn Libraries Digital Showcase Back to School Workshops series in August 2020. You can view the video here (forthcoming).]]></summary></entry><entry><title type="html">An Update from the Scribes Team: Cairo Geniza Research</title><link href="http://localhost:4000/blog/2020-08-24-cairo-geniza-research/" rel="alternate" type="text/html" title="An Update from the Scribes Team: Cairo Geniza Research" /><published>2020-08-24T00:00:00-04:00</published><updated>2020-08-24T00:00:00-04:00</updated><id>http://localhost:4000/blog/2020-08-24-cairo-geniza-research</id><content type="html" xml:base="http://localhost:4000/blog/2020-08-24-cairo-geniza-research/"><![CDATA[Hi there, 

We hope you all are safe and well wherever you are. Thanks for participating in our 5,000+ volunteer community of #GenizaScribes! We wanted to share resources for learning more about Cairo Geniza research from our team and partners. 

## #FragmentFriday on Twitter

Dr. Marina Rustow, director of the Princeton Geniza Lab, has been putting together some Twitter threads for #FragmentFriday, including: 
- A [long vertical scroll](https://threadreaderapp.com/thread/1290007840732528640.html?utm_source=newsletter&utm_campaign=sotcg24aug2020) with an equally long social history
- A [12th-century court record](https://threadreaderapp.com/thread/1291857148734058497.html?utm_source=newsletter&utm_campaign=sotcg24aug2020) addressing medieval Samaritans
- A [rhyming set of gripes](https://threadreaderapp.com/thread/1294544346566598656.html?utm_source=newsletter&utm_campaign=sotcg24aug2020) about visiting ports on the Red Sea

These have been grouped together for easy reading via the [Thread Reader App](https://threadreaderapp.com/?utm_source=newsletter&utm_campaign=sotcg24aug2020), but you can follow Dr. Rustow directly on Twitter at [@mrustow](twitter.com/mrustow) for more fascinating histories.

If you’re looking for more Geniza deep dives, check out the [Fragment of the Month](https://www.lib.cam.ac.uk/collections/departments/taylor-schechter-genizah-research-unit/fragment-month?utm_source=newsletter&utm_campaign=sotcg24aug2020) from Cambridge University Libraries. The [July 2020 edition](https://www.lib.cam.ac.uk/collections/departments/taylor-schechter-genizah-research-unit/fragment-month/fotm-2020/fragment-6?utm_source=newsletter&utm_campaign=sotcg24aug2020), written by Dr. Ben Outhwaite, head of the Geniza Research unit, explores an 11th-century letter that inspired the 2016 novel The Convert by Stefan Hertmans. 

## Seforimchatter Podcast 

The latest episode of the [Seforimchatter podcast](https://seforimchatter.buzzsprout.com/1218638?utm_source=newsletter&utm_campaign=sotcg24aug2020) featured Dr. Eve Krakowski, assistant professor of Near Eastern Studies and the Program in Judaic Studies at Princeton University. In it, Krakowski discusses the Cairo Geniza, its history, its uses today, and much more. The Seforimchatter podcast is dedicated to the discussion of Seforim (holy texts and works pertaining to them), Jewish (non-sacred) Books, and Jewish History. You can find the podcast on a variety of platforms, or listen to this episode [here](https://seforimchatter.buzzsprout.com/1218638/5041169-with-prof-eve-krakowski-discussing-the-cairo-geniza?utm_source=newsletter&utm_campaign=sotcg24aug2020). 

After reading through these exciting links, you can join us in classifying and transcribing Cairo Geniza fragments at [scribesofthecairogeniza.org](https://www.scribesofthecairogeniza.org/?utm_source=newsletter&utm_campaign=sotcg24aug2020). **Note: This project is also available in Hebrew and Arabic. To switch, use the language toggle in the top right of the page.**

As always, thanks for your help,

The Scribes of the Cairo Geniza Team]]></content><author><name>admin</name></author><category term="Scribes of the Cairo Geniza" /><category term="Scribes of the Cairo Geniza" /><summary type="html"><![CDATA[Hi there,]]></summary></entry><entry><title type="html">Data Wrangling with Google Sheets</title><link href="http://localhost:4000/blog/2020-07-06-digital-scholarship-bootcamp/" rel="alternate" type="text/html" title="Data Wrangling with Google Sheets" /><published>2020-07-06T00:00:00-04:00</published><updated>2020-07-06T00:00:00-04:00</updated><id>http://localhost:4000/blog/2020-07-06-digital-scholarship-bootcamp</id><content type="html" xml:base="http://localhost:4000/blog/2020-07-06-digital-scholarship-bootcamp/"><![CDATA[*The following transcript and slides were part of a workshop in the Digital Scholarship Bootcamp series at Penn Libraries in July 2020. The recording of this workshop is available [here](http://www.kaltura.com/tiny/zkt69).*

![Title Slide - Data Wrangling with Google Sheets](https://judaicadh.github.io/assets/post-media/2020-07-06/google-sheets-12.jpg)

![About Emily Esten](https://judaicadh.github.io/assets/post-media/2020-07-06/google-sheets-10.jpg)

Some background on me: I am the Judaica Digital Humanities Coordinator in the Center for Research Data and Digital Scholarship here in the libraries, which means I work between Special Collections and the Center on projects related to Jewish history and culture. I wanted to run this workshop because Google Sheets is really commonplace in our work as scholars, and in particular I’ve made a lot of use of data wrangling tips to create the datasets I work with. In this workshop, we’ll be using some of those datasets I’ve created as an example of what we can do with Google Sheet functions. 

![Definitions](https://judaicadh.github.io/assets/post-media/2020-07-06/google-sheets-11.jpg)

So if you think back to algebra, an expression is a group of numbers, symbols and operators to show the value of something 
> 1+5

A formula is an expression with an equals sign in front of it, which tells the computer that you want to calculate this expression
> =1+5

A function is a predefined formula in Google Sheets that allows you to manipulate data and calculate strings and numbers. A function uses specific values and symbols in a particular order (called syntax). All functions are formulas, but not all formulas are functions. 
> =SUM(1,5)

You can also mix functions together to get a result, which is called “nesting”. We’re not going to do that in today’s session, but some of the things I’ve linked to in the **Next Steps** will show you how to do that. 

![Syntax of Function](https://judaicadh.github.io/assets/post-media/2020-07-06/google-sheets-1.jpg)

The most important thing to remember with any function is the syntax. You'll see within the case studies the syntax for any specific function, but the basic syntax for anything looks like the following:
* the **equals sign**, which tells Google Sheets that you want to calculate this expression
* the **function name**, which tells Google Sheets that you're about to use a specific function 
* the **argument**, which provides the data necessary to use that function. The argument section can refer to individual cells, cell ranges, text, numbers, values. Depending on the function, you may need to input multiple arguments. In the case above, I've provided a *range* - a group of cells. A range is written as two cells, separated by a colon. 

In the case of functions and formulas, the “argument” section can refer to a lot of different things depending on what you're attempting to do - a string, a number, an individual cell, and/or cell ranges. Depending on the function, you may include one argument or multiple arguments.
> = SUM(1,5) features two arguments
=SUM(A1:A3) only features one (the cell range). 

![Types of Functions](https://judaicadh.github.io/assets/post-media/2020-07-06/google-sheets-3.jpg)

There are over [400 functions](https://support.google.com/docs/table/25273?hl=en) in Google Sheets. Most of these functions also work in Microsoft Excel, but I’m doing this in Google Sheets because my work with data often involves right-to-left languages, which are handled slightly better here than in Excel. 

These Google Sheets functions are grouped into types - the bolded types are the ones I’m going to discuss today, but any of these hundreds could be valuable to your data wrangling experience.

![Syntax of Function](https://judaicadh.github.io/assets/post-media/2020-07-06/google-sheets-2.jpg)
 
The other nice thing about functions is if you can’t remember how to write one, you can always use the functions button to find and select the one you’d like to use in a particular case. 

Okay! If you already have access to the Google Sheets, great! You can make a copy of the one I’m working on and follow along by going to [this link](https://docs.google.com/presentation/d/1Sh73KHRrJEGAI8EAGLJWXMmUojX2ApRJ4kOFIIsBKCo/edit?usp=sharing) and making a copy of the Google Sheets file. All the case studies follow the same structure: you can see the dataset, some questions below, and then at the bottom are some functions relevant to this case study’s question. 

# CASE 1: MATH

![List of Math Functions, pt. 1](https://judaicadh.github.io/assets/post-media/2020-07-06/google-sheets-4.jpg)

![List of Math Functions, pt. 2](https://judaicadh.github.io/assets/post-media/2020-07-06/google-sheets-5.jpg)

In this first case study, math, are all basic mathematical operations you might remember from algebra, or operations for providing count and frequency information. 

* **SUM** provides the sum of values in a range
* **AVERAGE** provides the average value in a range
* **MODE** provides the most common value in a range.
* **MAX** provides the highest value in a range.  
* **MIN** provides the lowest value in a range.
* **COUNT** provides the number of numeric values in range. 
* **COUNTA** provides the number of any type of values in a range. 
* **COUNTUNIQUE** provides a number of unique values in a range, removing duplicates from your count.
* **COUNTIF** provides a number of values matching criteria in one range
* **COUNTIFS** provides a number of values that match multiple criteria in multiple ranges. 

![Screenshot of Case 1 Spreadsheet](https://judaicadh.github.io/assets/post-media/2020-07-06/google-sheets-13.jpg)

This is a bibliographic dataset, with some information about monographs published prior to 1900. I want to find some quantitative information about the dataset to get a sense of what I’m looking at.

*View the worksheet* [here](https://docs.google.com/spreadsheets/d/15qlFC78I1VpW_LCkhyNN6J9U-BG0yQInsM8EfBQxB3c/edit?usp=sharing).

* What is the average year of this dataset?
> =AVERAGE(B4:B21)
>
> 1866

* What is the most common year in this dataset?
>=MODE(B4:B21) 
>
> 1898

* What is the highest year in this dataset?
> =MAX(B4:B21)
>
> 1900

* What is the lowest year in this dataset?
> =MIN(B4:B21)
>
> 1807

* How many unique years are in this dataset?
> =COUNTUNIQUE(B4:B21)
>
> 15

* How many entries are in this dataset?
> =COUNT(B4:B21)
>
> 18

* How many unique locations are in this dataset?
> =COUNTUNIQUE(D4:D21)
>
> 5

* How many books were published in New York, NY?
> =COUNTIF(D4:D21, "New York, NY")
>
> 9

* How many books were published in Boston, MA, by D. Lothrop?
> =COUNTIFS(D4:D21, "Boston, MA", E4:E21, "D. Lothrop")
>
> 2

# CASE 2: TEXT

![List of Text Functions, pt. 1](https://judaicadh.github.io/assets/post-media/2020-07-06/google-sheets-6.jpg)

![List of Text Functions, pt. 2](https://judaicadh.github.io/assets/post-media/2020-07-06/google-sheets-7.jpg)

So in this second case study, text, we’re interested in cleaning some of this data as opposed to answering specific questions. These functions in the text category clean the data by removing characters, converting data types, cutting up, replacing, substituting, or piecing together strings. 

* **TEXT** converts a number into a string, based on a specified format. This could be a date, a decimal, a time, more columns. 
* **VALUE** does the opposite - it converts a string into a number, based on a specified format. 
* **TO_DATE** is pretty self-explanatory: it does what VALUE does, but specifically for a specified date format.
* **SUBSTITUTE** replaces existing text with new text in a string
* **TEXTJOIN** combines text from multiple strings with a specifiable delimiter
* **CONCATENATE** combines strings. 
* **TRIM removes** leading and trailing spaces in a specified string.

![Screenshot of Case 2 Spreadsheet](https://judaicadh.github.io/assets/post-media/2020-07-06/google-sheets-14.jpg)

*View the worksheet* [here](https://docs.google.com/spreadsheets/d/15qlFC78I1VpW_LCkhyNN6J9U-BG0yQInsM8EfBQxB3c/edit?usp=sharing).

This is a dataset containing metadata from a manuscript collection here in the libraries. But it’s not exactly formatted the way I would like it to be. These functions can help me to edit the dataset.   

* For SMBx1FF8_14, convert the year into a string in the following format (#,###).
> =TEXT(D3, "#,###")
>
> 1,851

* For SMBx1FF10_8, convert the Gregorian date into a numerical date.
> =TO_DATE(C7)
>
> 5/20/1853

* For SMBx1FF10_13, substitute "Unknown Addressee" to "Solis, S" in the manuscript name.
> =SUBSTITUTE(B7, "Unknown Addressee", "Solis, S")
>
> Letter from Morais, Sabato to Solis, S. Philadelphia, PA; May 1853

* For SMBx1FF8_6, join the city and the state, separated by a comma.
> =CONCATENATE(E5,", ",F5) OR =TEXTJOIN(", ",TRUE,E5:F5) works here 
>
> Long Branch, NJ

* For SMBx17FF1_1, trim the spaces from the manuscript name.  
> =TRIM(B4)
>
> Letter from Bernal, A. I. H. to Morais, Sabato. Louisville, KY; Jun 1851

# CASE 3: WEB

![List of Web Functions](https://judaicadh.github.io/assets/post-media/2020-07-06/google-sheets-8.jpg)

In this third case study, web, we can use these formulas to import, export, or encode specific information from a web service on the Internet. 

* **ISURL** will check valid URLs - if it is a valid URL, it returns true; otherwise it returns false. This works whether or not your link is hyperlinked (with the blue font and underline). 
* **ENCODEURL** turns your text string into a link, which can be really helpful in passing it to some of these next functions. 
* **IMPORTDATA** imports the data from a URL of a .csv or .tsv file, rather than downloading the file and uploading or copying/pasting it yourself.
* **IMPORTXML** imports the data from an XML file. 
* **IMPORTHTML** imports data from a table or list within an HTML page. 

![Screenshot of Case 3 Spreadsheet](https://judaicadh.github.io/assets/post-media/2020-07-06/google-sheets-15.jpg)

*View the worksheet* [here](https://docs.google.com/spreadsheets/d/15qlFC78I1VpW_LCkhyNN6J9U-BG0yQInsM8EfBQxB3c/edit?usp=sharing).

In this case study, we're importing data from existing datasets from [OPenn](http://openn.library.upenn.edu/) and the [Judaica DH GitHub repository](https://github.com/judaicadh). 

* Import all attributes that are named "mainLang" from the XML file in Row 4. 
> =IMPORTXML(C4,"@mainLang")
>
> jrb 

* Import the data from the CSV in Row 3. 
> =IMPORTDATA(C3)

* Import the data from the table from the HTML page in Row 5.
> =IMPORTHTML(C5,"table", 1)

# CASE 4: VLOOKUP & QUERY

![List of VLOOKUP and QUERY functions](https://judaicadh.github.io/assets/post-media/2020-07-06/google-sheets-9.jpg)

In this fourth case study, lookup and reference, either looks up information about the data inside the cell or about the cell itself. 

* **VLOOKUP** is short for “vertical lookup” and it looks down the first column of a range for a specific key, and returns the value of a specified cell in the row found. It can work within a sheet as well as across sheets or worksheets.

* **QUERY** is arguably the most useful function in Google Sheets but the hardest one we’ll tackle today. It runs a language query across your data using database-type commands. 

![Screenshot of Case 4 Spreadsheet](https://judaicadh.github.io/assets/post-media/2020-07-06/google-sheets-16.jpg)

*View the worksheet* [here](https://docs.google.com/spreadsheets/d/15qlFC78I1VpW_LCkhyNN6J9U-BG0yQInsM8EfBQxB3c/edit?usp=sharing).

In this case study, we're working with data from the previous four case studies to look up more information about the data we've imported and collected.

* Search for the author_editor of the item with the pid "supp0785" from the CASE1 sheet.
> =VLOOKUP("supp0785",CASE1!A3:E21,3,FALSE)
>
> Alden, Isabella Macdonald, ed.

* Search for the manuscript name of the item with Box/Folder Location "SMBx1FF8_14" from the CASE2 sheet.
> =VLOOKUP("SMBx1FF8_14",CASE2!A2:F8,2,FALSE)
>
> Letter from Solis, S. to Weil, Clara E. Philadelphia, PA; May 1851

* Search for the file named "George Washington" from the CASE3 sheet.
> =VLOOKUP("George Washington",CASE3!A2:E25,1,FALSE). You will get #N/A because that doesn't exist in CASE3
>
> Alden, Isabella Macdonald, ed.

* Query the average year of the dataset in the CASE1 sheet. 
> =QUERY(CASE1!A3:E21,"select avg(B)")
>
> avg YEAR
>
> 1866

* Query the manuscript name where the year is 1853 in the CASE 2 sheet.
> =QUERY(CASE2!A2:F8, "select (B) where (D) > 1852")
>
> Name
>
> Letter from Morais, Sabato to Unknown Addressee. Philadelphia, PA; May 1853
>
> Letter from Labatt, D. C. to Morais, Sabato. New Orleans, LA; Sep 1853

# Next Steps with Google Sheets

Functions are one way to wrangle your data, but there are so many other things you can do and learn.

* [21 Awesome Things Google Sheets Can Do - Tips & Tricks (Benjamin Mangold)](https://www.lovesdata.com/blog/google-sheets-tips)
* [Custom Functions in Google Sheets (Google)](https://developers.google.com/apps-script/guides/sheets/functions)
* [Data Wrangling in Google Sheets: Debating Motions Example (Jessica Yung)](https://www.jessicayung.com/data-wrangling-in-google-sheets-debating-motions-example/ )
* [Google Sheets function list (Magnus Adielsson, Richard Barnes, Peter Kupfer, Iain Roberts, Jean Hollis Weber)](https://support.google.com/docs/table/25273?hl=en)
* [Google Sheets Tutorial (GCF Global)](https://edu.gcfglobal.org/en/googlespreadsheets/)
* [How We Helped Our Reporters Learn to Love Spreadsheets (Lindsey Rogers Cook)](https://open.nytimes.com/how-we-helped-our-reporters-learn-to-love-spreadsheets-adc43a93b919) and [Data Training Materials  (Lindsey Rogers Cook)](https://drive.google.com/drive/u/0/folders/1ZS57_40tWuIB7tV4APVMmTZ-5PXDwX9w) 
* [How to Use the QUERY Function in Google Sheets (Ben Stockton)](https://www.howtogeek.com/450465/how-to-use-the-query-function-in-google-sheets/)
* [Scraping, Transforming, and Enriching Bibliographic Data with Google Sheets (Michael P. Williams, Penn Libraries)](https://www.slideshare.net/MichaelWilliams513/scraping-transforming-and-enriching-bibliographic-data-with-google-sheets)
* [The Ultimate Guide to Google Sheets VLOOKUP Function (with examples) (Productivity Hotspot)](https://productivityspot.com/google-sheets-vlookup-function/)
* [Using IFERROR Function in Google Sheets (Productivity Spot)](https://productivityspot.com/iferror-function-google-sheets/)]]></content><author><name>emily-esten</name></author><category term="Presentations" /><category term="Conferences" /><summary type="html"><![CDATA[The following transcript and slides were part of a workshop in the Digital Scholarship Bootcamp series at Penn Libraries in July 2020. The recording of this workshop is available here.]]></summary></entry><entry><title type="html">#AJL2020: Judaica Digital Humanities at the Penn Libraries Overview</title><link href="http://localhost:4000/blog/ajl2020/" rel="alternate" type="text/html" title="#AJL2020: Judaica Digital Humanities at the Penn Libraries Overview" /><published>2020-07-02T00:00:00-04:00</published><updated>2020-07-02T00:00:00-04:00</updated><id>http://localhost:4000/blog/ajl2020</id><content type="html" xml:base="http://localhost:4000/blog/ajl2020/"><![CDATA[![Judaica Digital Humanities at the Penn Libraries - Title Slide](https://judaicadh.github.io/assets/post-media/ajl2020/ajl2020-1.jpg)

*The following transcript and slides were part of a panel at the Association of Jewish Libraries virtual conference in July 2020.*

![About Penn Libraries and Judaica DH](https://judaicadh.github.io/assets/post-media/ajl2020/ajl2020-2.jpg)

The University of Pennsylvania Libraries has a mission to foster innovative approaches to integrating material and digital research, while advocating for open data (read more about[our history](https://judaicadh.library.upenn.edu/history/) or [Penn Libraries](https://judaicadh.library.upenn.edu/libraries/)). 

Since 2016, the Center for Research Data and Digital Scholarship has formally developed a program of creative research and development related to Jewish Studies. This program, known informally as Judaica DH, and of which I am the [project coordinator](https://judaicadh.library.upenn.edu/people/emily-esten/), encompasses digital humanities, historical and public scholarship to center Jewish history and culture. 

![Overview of Current Project at Judaica DH at the Penn Libraries](https://judaicadh.github.io/assets/post-media/ajl2020/ajl2020-3.jpg)

Judaica DH incorporates the principles of technology, collaboration, and Jewish diaspora into all facets of our work. You can view a gallery of all current and legacy projects on our [project page](https://judaicadh.library.upenn.edu/projects/) - these are some of current projects. Our projects have involved text, visual, and spatial analyses; we've built digital editions and archives; we work in open data and have created multiple datasets; and we emphasize making projects that can serve as models and first steps towards larger initiatives within the Libraries. Today, I want to give you all an introduction of how these principles structure our program's research and development.

![Principle 1: Technology](https://judaicadh.github.io/assets/post-media/ajl2020/ajl2020-4.jpg)

Our first principle is *technology*. We use digital technologies to augment and transform the ways in which we advance the field of Jewish Studies. By experimenting with platforms, tools, and methodologies, we deepen and broaden our understanding of Jewish history, texts, and cultures 

![Digital Second Edition of Judaica Americana](https://judaicadh.github.io/assets/post-media/ajl2020/ajl2020-5.jpg)

Our most recent project just launched this week: the [Digital Second Edition of Judaica Americana](https://judaicadh.library.upenn.edu/work/judaica-americana/). Based on Robert Singerman's 1990 bibliography, this project facilitated the creation and creative re-use of bibliographic datasets for documenting monographs and serials related to the research, activity, and culture of American Jewish communities. Visitors can search the database’s 9,600+ bibliographic entries by author, language, holding institution, and various tags, as well as find open-access links to digitized Jewish monographs, serials, and periodicals, when available.

To the principle of technology, our documentation throughout this project has emphasized building a bibliographic tool for students of early American Jewish history and a model for DH scholars. As you can read in [a project documentation blog post](https://judaicadh.library.upenn.edu/blog/about-singermanja2), this project from its initial vision has been about prioritizing open access to materials. And we do that with every step of our work. The electronic edition of *Judaica Americana* as well as the derivative datasets are available in our open-access repository. The code for constructing those datasets is publicly available and citable on GitHub with a DOI through Zenodo; and the database links to open-access materials within our libraries and repositories like HathiTrust and Internet Archive among others. We went into the project with a technological vision that would broaden engagement with early American Jewish publishing.

![Principle 2: Collaboration](https://judaicadh.github.io/assets/post-media/ajl2020/ajl2020-6.jpg)

And then we have our second principle, *collaboration*. Building on Penn’s commitment to integrate knowledge as well as my personal commitment in public engagement, we work with our collaborators to promote a public and participatory humanities. Bringing different disciplines and approaches together to lead scholarship in new directions, we believe Judaica DH at the Penn Libraries should sustain a collaborative network of trust, respect, and transparent communication. This collaborative spirit begins with our foundational partnership between the Kislak Center for Special Collections, Rare Books and Manuscripts and the Center for Research Data and Digital Scholarship.

![Scribes of the Cairo Geniza](https://judaicadh.github.io/assets/post-media/ajl2020/ajl2020-7.jpg) 

In addition to internal collaborations, we’ve also emphasized external collaborations and public humanities partnerships. In our crowdsourcing transcription initiative, [Scribes of the Cairo Geniza](https://judaicadh.library.upenn.edu/work/cairo-geniza/), we bring together researchers, institutions, and citizen scientists around the globe to create a new, virtual community around historic manuscript fragments, recording their own experiences along the way. We have research partners invested in project planning, development, and outreach; image partners who have contributed their materials; and community presentations to further engage Jewish communities in participating. Collaboration within our program serves as a pedagogical tool for Jewish literacy among virtual and in-person communities, and as a project management tool for investing in our colleagues at Penn and elsewhere. 

![Principle 3: Diaspora](https://judaicadh.github.io/assets/post-media/ajl2020/ajl2020-8.jpg)

Which ties into our third principle of *Jewish diaspora*. Our goal is to ultimately support the study of, access to, and re-use of data and cultural objects documenting the creativity of Jewish civilization. As our projects bring together dispersed communities and materials, we think critically about how best to represent and take into account diverse facets of Jewish diasporic history, culture, and thought online. And digital scholarship allowes us to do that by emphasizing the connection between digital and diasporic. As other cultural digital praxis like Black DH and Latinx DH have noted, describing the interaction of places, times, languages, identities, and narratives that characterize cultures and materials of the Jewish diaspora require a multidimensionality that digital scholarship provides. 

![Project Examples of Diaspora](https://judaicadh.github.io/assets/post-media/ajl2020/ajl2020-9.jpg)

I think this is difficult to discuss and provide in just one example because it is fundamental to all the presenters on this panel in our work on digital Jewish projects. So I've highlighted three projects from our program both past and present for which DH methods have augmented that relationship. 

* In the digital reunification of Geniza materials across collections, [Scribes of the Cairo Geniza](https://judaicadh.library.upenn.edu/work/cairo-geniza/) discusses how this separation occurred and how their eventual digitization has rendered them accessible.
* [Mapping the Kaplan Collection](https://judaicadh.library.upenn.edu/work/kaplan-map/) was a pilot mapping project to explore the [Arnold and Deanne Kaplan Collection of Early American Judaica](https://kaplan.exhibits.library.upenn.edu/) here and Penn and its documenting of the social and economic development of early Jewish life in the Western Hemisphere. 
* By making these writings and correspondence of Sabato Morais digitally available through the [Sabato Morais Digital Repository](https://judaicadh.library.upenn.edu/work/morais-repository/), researchers have access to primary sources that document the development of observant Jewish life in the broad context of Victorian culture on both sides of the Atlantic during the nineteenth century.

![2021: Looking Forward](https://judaicadh.github.io/assets/post-media/ajl2020/ajl2020-10.jpg)

These projects highlight the variety of ways that our principles facilitate instruction and content of Jewish Studies on local and international levels while engaging with digital humanities tools, technologies, and methodologies for experimentation. As the program enters its next phase in 2021, with the world’s first endowed position in Judaica digital humanities, we [plan to take on](/history) a new set of projects at Penn Libraries. 

We plan to include modeling digital humanities research and publication best practices through our projects; collaboration and outreach with the rest of Penn Judaica; and community events outside the university to ensure accessibility and usage of our materials. It's not enough for us to digitize and build these digital projects; we must also work to engage with the academic and public communities that can make use of them. We will additionally improve our professionalization efforts as a program, by maintaining a well-documented Github organization;  revamping our website to include project history and documentation; and sharing our scholarship through journal submissions, digital repositories, blogs, conference and workshop presentations. Our work will emphasize collaborative practice, value a public and inclusive humanities, and continue to model the possibilities of digital projects in the #DHJewish community. 

*This talk, especially in its discussion of the third principle, borrows from [Jessica Marie Johnson’s “Diaspora”](https://digitalpedagogy.mla.hcommons.org/keywords/diaspora/), [Franceso Spagnolo’s Mapping Diasporas: Jewish Culture, Museums, and Digital Humanities”](http://digitalhumanities.berkeley.edu/courses/mapping-diasporas-jewish-culture-museums-and-digital-humanities), [Dov Winer's "The role of digital/online resources in the Jewish Diaspora communities"](https://revistas.pucsp.br/circumhc/article/view/45771/30274), [Michelle Chesner's "JS/DH: An Introduction to Jewish Studies/Digital Humanities Resources"](https://hcommons.org/deposits/item/hc:18725) and the [2008 “Digital Humanities and African American/African Diaspora Studies” Conference at the University of Maryland, College Park](https://archive.mith.umd.edu/diaspora2008/about.php.html).*]]></content><author><name>emily-esten</name></author><category term="Presentations" /><category term="Conferences" /><summary type="html"><![CDATA[]]></summary></entry><entry><title type="html">Building the Digital Second Edition of Robert Singerman’s Judaica Americana</title><link href="http://localhost:4000/blog/about-singermanja2/" rel="alternate" type="text/html" title="Building the Digital Second Edition of Robert Singerman’s Judaica Americana" /><published>2020-06-30T00:00:00-04:00</published><updated>2020-06-30T00:00:00-04:00</updated><id>http://localhost:4000/blog/about-singermanja2</id><content type="html" xml:base="http://localhost:4000/blog/about-singermanja2/"><![CDATA[As the project manager and developer for [Judaica Digital Humanities at the Penn Libraries](http://judaicadh.library.upenn.edu), I’m excited to announce the launch of the [Digital Second Edition of Judaica Americana](https://singermanja2.exhibits.library.upenn.edu/). This is an Omeka database which draws from Robert Singerman’s *Judaica Americana,* a bibliography chronicling American Jewish book production until 1900. The Digital Second Edition contains 3,000 supplemental entries to the print edition. The project’s features allow users to search the bibliography by author, language, holding institution, and various tags, as well as find open-access links to digitized Jewish monographs, serials, and periodicals.

You can view the project at [*singermanja2.exhibits.library.upenn.edu/*](https://singermanja2.exhibits.library.upenn.edu/).
Additional information about the project can be found on the Judaica DH website at [*judaicadh.github.io/work/judaica-americana*](http://judaicadh.github.io/work/judaica-americana).

# About *Judaica Americana*

In July 2019, Robert Singerman, emeritus university librarian at the University of Florida, donated to the Penn Libraries the draft of the full text and the copyright to his revised second edition of *Judaica Americana*. The first edition, issued in 1990, is an award-winning, magisterial two-volume bibliography of American Jewish publications before 1900. The print edition of *Judaica Americana* was sponsored by the Center for the Study of the American Jewish Experience, Hebrew Union College-Jewish Institute of Religion, and published by Greenwood Press as part of the Bibliographies and Indexes in American History.

In it, Singerman identified just over 6,500+ monographic and serial publications, presented with meticulous bibliographical descriptions, classification explanations, and holdings information, i.e., the names of collections where copies are known to be held. His bibliography chronicled American Jewish book production from the 17th century to the beginning of the twentieth century. Taken as a whole, Singerman’s bibliography provides extensive and authoritative documentation of American Jewish communal activity and growth before 1901.

When starting the project, I read book reviews of *Judaica Americana* to understand what exactly we were attempting to transform. In addition to building on the work of existing American Jewish bibliographies like [*Rosenbach’s*](https://archive.org/details/americanjewishbi0000rose), several reviews mentioned Singerman’s use of multiple bibliographic techniques, by which they meant OCLC, RLIN, and traditional onsite visits to institutions. For me, that was a key detail, recognizing Singerman’s bibliography as a distinct moment in time between past bibliographies (which required someone to physically view and document each monograph) and the use of online databases in scholarly communication.

Bibliographer [*Nathan Kaganoff’s review of the first edition*](http://www.jstor.org/stable/23884484) was not the most positive review, but provided crucial insight into how our project could augment and transform Singerman’s work. Kaganoff asked four questions in his review:

1)  Does this bibliography present new data or information that was not previously available?

2)  How does it appear physically compared to the earlier bibliographies? Does the use of a computer bring with it any unusual elements or features?

3)  Have we learned anything new about the quantity of American Jewish printed material? How has this material been preserved and what might we still anticipate finding in the future?

4)  Does “Singerman” now become the definitive bibliographic tool for students of early American Jewish history rather than “Rosenbach”?

For Kaganoff, the print edition fulfilled Questions 1 and 3, but fell short in Questions 2 and 4. I found this review really helpful in framing the value of our project for scholars and the steps we needed to take at each stage of the process. Kaganoff’s questions are similar to those digital scholarship practitioners use to evaluate digital projects, and these were key areas in which our project could expand upon the print edition.

# Building the Project 
**First Steps**

![White board with text from planning stages](https://judaicadh.github.io/assets/post-media/singermanja2/2020-06-03-singermanja2-1.jpg)

*One of our boards following the User Analysis model from Yale DH.*

This was the first project I undertook from start-to-finish at Penn, and I used this as an opportunity to learn best techniques for engaging my colleagues, understanding library infrastructure, and segmenting the project into clear goals. To guide us in our project planning process, we used elements of the [*YaleDH Lab Project Planning Toolkit*](https://dhlab.yale.edu/guides/project-planning.html). Most helpful for us were the [*Lean Canvas*](https://dhlab.yale.edu/assets/docs/DH-LeanCanvas.pdf) and [*User Analysis*](https://dhlab.yale.edu/assets/docs/DH-User-Analysis.pdf) worksheets, which identified key user audiences and experiences we wanted to facilitate with both the dataset and the database.

We also used this time to talk about existing projects related to ours. In particular, we took inspiration from [*Women in Book History*](https://www.womensbookhistory.org/) and the [*Footprints: Jewish Books Through Space and Time*](https://footprints.ctl.columbia.edu/), both of which are databases for book history. We really admired how both projects had clean, clear interfaces, and contextualized their projects for user engagement.

As part of the Jekyll and Python Working Groups at Penn, I also spent a lot of time with the team working on the [*Digital Beehive*](https://kislakcenter.github.io/digital-beehive/) here at Penn. The Digital Beehive project is a working digital edition of Francis Daniel Pastorius’ Beehive Manuscript, a commonplace book begun in 1696. While the Digital Beehive’s data is a lot more complicated than the datasets we used, the project’s interest in understanding how can digital formats faithfully replicate pre-digital data systems provided a good example of how a similar project could be built in Jekyll.

We also spent a lot of time referring to the physical book at this point, so I always had the library copy on my desk. It was often a conduit for asking questions in the planning stage about how we wanted to represent things digitally. Some of the questions:

-   Why does Singerman use asterisks here?

-   What is the author when Singerman uses an LOC header or an institution?

-   In the document, there were some odd formatting issues. What of this part of the notes and which of this is part of the entry?

-   Where should entries with uncertain years (like 184-?) be placed?

-   What fields are explicitly listed and can be extracted easily, and which ones are inferred within an entry?

Over the course of a few meetings and rounds of editing, we completed a project charter that borrowed sections from [*Yale DH Lab*](https://dhlab.yale.edu/assets/docs/ProjectCharter-RPG.pdf), [*PM4DH at Emory*](https://scholarblogs.emory.edu/pm4dh/creating-a-project-charter/), and [*Princeton DH Charters*](https://cdh.princeton.edu/research/project-management/charters/) to address all the questions we had in mind.

**The Open-Access Edition**

![Announcement on Medium](https://judaicadh.github.io/assets/post-media/singermanja2/2020-06-03-singermanja2-2.jpg)

*A screenshot of our Medium announcement about the ScholarlyCommons repository.*

The dataset for the open-access edition, as well as the process of converting the chronological file into a dataset, is discussed a forthcoming article for [*Journal of Open Humanities Data*](https://doi.org/10.5334/johd.15). I borrowed from my experience working on the [*1853 New York Crystal Palace*](http://cds.library.brown.edu/projects/crystalpalace/) to [*write a script*](https://github.com/judaicadh/ja2-scripts/blob/master/extract_singerman.py) that separated out id numbers, year, entry, notes, and holdings information based on the structure of the original text. This was further cleaned through a combination of OpenRefine and manual review.

There were probably more effective ways to write this script that would not have been as labor-intensive for data cleaning, but this balance worked for me. It also helped us answer a lot of questions along the way, such as how we wanted to clean fields like “Location”, “Publisher”, “Author/Editor”.

After merging the revised second edition draft with additional supplemental entries, and converting the chronological file into a dataset, both were deposited into a project-specific [*ScholarlyCommons repository*](https://repository.upenn.edu/judaica_americana/). At this time, we [*announced*](https://medium.com/@judaicadh/explore-robert-singermans-judaica-americana-a33c8721707d) the open-access edition to the public and the start of our project.

We agreed with Singerman at this point that any edits or additions to the dataset would not be uploaded to ScholarlyCommons until the end of the project. For any new entries to the supplement that Singerman would send us, we created a Google form that structured data entry for the dataset. (Over the course of the project, Singerman sent eleven updates to the database, with five to fifteen new entries each time.) Establishing that boundary early on in our process helped us be consistent.

**Augmenting the Dataset**

![Scanned index page, with columns of words](https://judaicadh.github.io/assets/post-media/singermanja2/2020-06-03-singermanja2-3.png)

*A scan of the Singerman index, which includes nearly 12,000 headers.*

At this point, we were ready to augment the dataset in a few ways:

-   We knew that we wanted to have “Language” as a searchable field in the dataset, as many languages are represented in this dataset. Singerman typically identifies this information in the Notes if multiple languages are present in the text. We separated language in two categories: language of the *text* (the “Language” field) and language of the *title* (the “Language-Title” field).

-   Prior to the start of this project, Camille Davis had identified open-access links to digital facsimiles of each entry (when possible) on WorldCat, HathiTrust, GoogleBooks, Internet Archive, or in other digital repositories. Davis also included the vernacular titles of entries listed in Yosef Goldman’s *Hebrew Printing in America, 1735-1926: A History and Annotated Bibliography*. Both of Davis’s datasets were merged with the JA2 dataset.

-   We also wanted to use the tagging feature on Omeka to include the index headers of the original publication’s index. This process is discussed in a forthcoming article for [*Journal of Open Humanities Data*](https://doi.org/10.5334/johd.15), but involves performing OCR to extract text and then associate specific locators (in this case, Singerman ID numbers) with headers. Penn Libraries staff scanned the 150+ pages of the index as three separate PDF files. I then used [tess](https://github.com/senderle/tess), a Python script by Penn Libraries’ Digital Humanities Librarian Jonathan Scott Enderle for converting PDFs to TIFFs and performing OCR with tesseract, to create three separate text files. The text files were combined into one, with each line serving as a heading followed by a list of locators. The 12,000+ entries of the index were then separated row by row into a key/value structure with two distinct columns, split on the first comma and reviewed manually for quality control.

-   In addition to the chronological file, JA includes a union list of nineteenth-century serials that fit Singerman’s criteria. We had originally chosen not to include the serials as part of our dataset, but seeing resources like Ohio State University’s [*Union List of Digitized Jewish Historic Newspapers, Periodicals and e-Journals*](https://library.osu.edu/projects/hebrew-lexicon/Jewish-Press_files/sheet002.htm) encouraged us to make the effort to include them. We restructured the Python script used for extracting entries for the original dataset into one that could be used to extract serial entries.

While we initially proposed building the project on a static site in order to have full control over the site’s display, it was around this stage that we switched to Omeka instead. Working with Omeka allowed us to have an established project interface to scale up for future phases of the project. It also brought together a variety of library departments for consultation and support in a way that we may not have been able to do on another platform. It engaged a lot more staff in the conversation of our project, yielding new insights into its development.

We worked with the library's Learning and Technology Services division to get installations of Omeka on the library server. By the end of February, we shared the first draft of the site with our project team, which featured the first 500 entries in chronological order. We had built the incremental loading of data into the project charter, initially with 5%, 10%, 50%, etc. In practice, those percentages didn’t make sense, so we scaled this incremental practice to specific numbers and focused our questions around that data for our team to go in and review.

**Drafting the Site**

![Screenshot of early site navigation](https://judaicadh.github.io/assets/post-media/singermanja2/2020-06-03-singermanja2-4.jpg)

*A screenshot of the navigation for the second draft of the site*

By the end of March, we shared the second draft of the site with the team, including the first 1,000 entries in chronological order. Some of the changes we made for this draft:

-   We made two additional changes to the dataset specifically for the database:

    -   Using the “Dublin Core: Metadata” description, we included the full entry as displayed in the text - the bibliographic entry, any notes provided by Singerman, and the holdings information in full (see below). This allows users to view all this content while browsing, simulating the experience of reading the physical book.

    -   In the “Holdings” field, Singerman occasionally provides notes or specific volume information about a library’s copy of the monograph. To make that field searchable by institution, we maintained the codes but removed the notes from the “Holdings” field.

-   We added a “Using JA2” page to include information about how browse entries work, descriptions for each metadata field, the abbreviations used by Singerman in the Notes field, and the Library Symbols used in the text. (We took inspiration from the information research aid for [*Women in Book History*](https://www.womensbookhistory.org/the-bibliography)!)

-   We added Singerman’s introduction to the site and hyperlinked footnotes to facilitate easy reading.

-   At this point, we decided to make a custom Omeka theme. We had originally used a [*custom Omeka theme for Penn Libraries Special Collections*](https://github.com/upenn-libraries/upennlib_sc_shadowpage_bootstrap), but wanted to make changes to the images and CSS of the page to match our project needs.

**More Data & Customization**

![Header image for the site: shelf of books in the background with white box at center. Penn Libraries logo followed by "Digital Second Edition of Judaica Americana"](https://judaicadh.github.io/assets/post-media/singermanja2/2020-06-03-singermanja2-5.png)

*The graphic header for the site - the books in the background comes from a \#shelfie at the [*Library at the Katz Center for Advanced Judaic Studies*](https://business.facebook.com/katzcenterupenn/photos/a.716387478439866/2672788819466379/?type=3&theater).)*

By the end of April, we shared the third draft of the site with the team, including all the entries in chronological order. Some of the changes we made for this draft:

-   We previously had not included the open-access links in the project. We added them here for our beta testers to review, and included Penn-specific links for any entries for which Penn has digitized copies in Colenda or digital repositories.

-   We made a custom graphic header for the site, modeled after other library project graphics like the [*Kaplan Collection*](https://kaplan.exhibits.library.upenn.edu/).

-   We uploaded the first version of the custom theme, which included:

    -   Adding an option to sort by Year
    -   Removing the option to sort by Creator (since we don’t use that metadata)
    -   CSS changes in the footer

**Final Draft & Next Steps**

We launched the final version of the site in May. Most of the changes here were small edits to the dataset we had noticed in user review. We also made changes for database’s “Browse” pages to reflect as closely as possible the original draft in chronological order by publication. We used Omeka's collection feature to separate out the Chronological File (sorted in chronological order) and the Union List (sorted by title). 

Since October 2019, the PDF of *Judaica Americana* on ScholarlyCommons has 1,125 downloads and the dataset 96 downloads. These files have been downloaded from 80 institutions and 96 countries. As of May 2020, there are 8,881 monograph entries in the database, including 2,936 supplemental entries added from the first edition. 58% of the original entries have WorldCat links, 18% have HathiTrust links, 10% have GoogleBooks links, and 6% have Internet Archive links.

During summer 2020, we plan to identify open-access links for the \~3,000 entries in the supplement, and improve existing links that may have broken in the past few years. We also hope to enter vernacular titles for more entries, especially those in the supplement.

There are three outstanding tasks that we hope to complete in future phases of the project:

-   In the print edition, Singerman transliterated titles in non-Roman languages; in the supplement, he was able to type in non-Hebrew characters. Using the Goldman-Kinsberg bibliography, we were able to include vernacular titles of Hebrew and Yiddish texts. We didn’t have the time and resources to build a plugin at this stage, but we would like to find and or develop a virtual keyboard plugin that would allow users to type and search for Hebrew characters within our site, rather than copying and pasting Hebrew text from elsewhere. We think this type of plugin would be useful for multilingual Omeka projects.

-   For now, only the entries indexed in the print edition have been tagged. We would also love to fully index the supplemental entries in order to expand the depth of search within the database.

-   We hope to include PDF files of the entries within Omeka for items in Penn’s collection, allowing for full-text search of these entries.

We set out to create an interactive digital edition of this rich bibliography and we can’t wait to see what discoveries can be made based on this data. We would love to see this project modeled in the creation of other enumerative bibliographies or digital library collections.

And while Singerman’s bibliography focuses on monograph holdings at various locations, we now have the opportunity to take this a step further and quantify the efforts of library digitization through projects like HathiTrust and Google Books. We hope this encourages others to identify digital facsimiles of their collections, whether on an institutional or cross-institutional level.

# Acknowledgements
----------------

Our full team is listed [*here*](https://singermanja2.exhibits.library.upenn.edu/credits-and-acknowledgments).

First and foremost, this project would not be possible without the generosity of Robert Singerman, who entrusted us with his extraordinary work. It is with his conceptualization, vision, and data curation that this project is possible.

Mitch Fraas and Arthur Kiron served as project directors, handling the project administration and mentor oversight to the project. Arthur Kiron was also responsible for developing the project vision, including serving as liaison with Robert Singerman, coordinating files, and providing quality control. Nicky Agate provided project administration support. 

I was responsible for the data preparation and project methodology. As the developer and designer, I designed the look and feel of the site, editing the Omeka theme that is used for the navigation and user interaction with the site. Senior developers Kate Lynch and Chris Clement, and DevOps Developer Andrew Kimball provided Omeka support on this project.

Many thanks to the distinguished scholars, librarians, and staff who generously provided guidance and assistance with the project, including: Michelle Chesner, Laurie Allen, Camille Davis, Laura Newman Eckstein, Doug Emery, Scott Enderle, Emily Morton Owens, Will Noel, and Jordan Rothschild.

### Additional Resources
--------------------

You can view the project at [*singermanja2.exhibits.library.upenn.edu/*](https://singermanja2.exhibits.library.upenn.edu/).
Additional information about the project can be found at [*judaicadh.github.io/work/judaica-americana*](http://judaicadh.github.io/work/judaica-americana).

**Publications**

-   Esten, Emily. “Digital Second Edition of Judaica Americana: A Bibliography of Publications to 1900” Journal of Open Humanities Data 6, no. 4, (2020). DOI: https://doi.org/10.5334/johd.15

-   We have a repository on ScholarlyCommons, University of Pennsylvania’s open access institutional repository, dedicated to resources for the project:

    -   Esten, Emily. “[*Dataset for Judaica Americana: A Bibliography of Publications to 1900*](https://repository.upenn.edu/judaica_americana/2)”. Scribes of the Cairo Geniza, Scholarly Commons, 2019. Web.

    -   Esten, Emily. “[*Dataset for Union List of Nineteenth-Century Jewish Serials Published in the United States*](https://repository.upenn.edu/judaica_americana/3/)”. Judaica Americana, Scholarly Commons, 2020. Web.

    -   Singerman, Robert. “[*Judaica Americana: A Bibliography of Publications to 1900*](https://repository.upenn.edu/judaica_americana/1)”. Judaica Americana, Scholarly Commons, 2019. Web.

-   The Python scripts used in this project are maintained in a [*GitHub repository*](https://github.com/judaicadh/ja2-scripts), including:

    -   Esten, Emily. “Extract\_singerman.py.” ja2-scripts, Github, accessed May 15, 2020, [*https://github.com/judaicadh/ja2-cleaning*](https://github.com/judaicadh/ja2-cleaning) DOI: 10.5281/zenodo.3894691

    -   Enderle, Jonathan Scott. “tess.py.” ja2-scripts, Github, accessed May 15, 2020, [*https://github.com/judaicadh/ja2-cleaning*](https://github.com/judaicadh/ja2-cleaning). (Forked from its original repository) DOI: 10.5281/zenodo.3894691

    -   Esten, Emily. “flip-index-headers.py.” ja2-scripts, Github, accessed May 15, 2020,[*https://github.com/judaicadh/ja2-cleaning*](https://github.com/judaicadh/ja2-cleaning) DOI: 10.5281/zenodo.3894691

    -   Esten, Emily. “extract-singerman-serials.py.” ja2-scripts, Github, accessed May 15, 2020, [*https://github.com/judaicadh/ja2-cleaning*](https://github.com/judaicadh/ja2-cleaning) DOI: 10.5281/zenodo.3894691

**Resources & Tools**

-   [*Omeka Classic*](https://omeka.org/)

-   [*Omeka theme for Penn Libraries Special Collections*](https://github.com/upenn-libraries/upennlib_sc_shadowpage_bootstrap)

-   [*OpenRefine*](https://openrefine.org/)

-   [*ScholarlyCommons*](https://repository.upenn.edu/)

-   [*Yale DHLab - DH Toolkit*](https://dhlab.yale.edu/guides/project-planning.html)

-   [*PM4DH at Emory*](https://scholarblogs.emory.edu/pm4dh/creating-a-project-charter/)

-   [*Princeton DH Charters*](https://cdh.princeton.edu/research/project-management/charters/)

**References**

-   Chesner, Michelle, ed., et al. “Footprints: Jewish Books Through Time and Place.” *Footprints: Jewish Books Through Time and Place*, Center for Teaching and Learning at Columbia University Libraries, [*https://footprints.ctl.columbia.edu/*](https://footprints.ctl.columbia.edu/).

-   Coker, Cait and Kate Ozment. [**Building the Women in Book History Bibliography, or Digital Enumerative Bibliography as Preservation of Feminist Labor.**](https://www.digitalhumanities.org/dhq/vol/13/3/000428/000428.html) 13, no. 3 (2019). Accessed May 14, 2020. [*https://www.digitalhumanities.org/dhq/vol/13/3/000428/000428.html*](https://www.digitalhumanities.org/dhq/vol/13/3/000428/000428.html).

-   Coker, Cait, and Kate Ozment. “Women in Book History Bibliography.” *Women in Book History Bibliography*, English Department at Texas A&M University, [*www.womensbookhistory.org/*](http://www.womensbookhistory.org/our-mission). Accessed May 14, 2020.

-   Croxall, Brian, Emily Esten, Steffani Gomez, Steven Lubar, and Patrick Rashleigh. “1853 New York Crystal Palace.” *1853 New York Crystal Palace*, Center for Digital Scholarship at Brown University Library, [*http://cds.library.brown.edu/projects/crystalpalace/*](http://cds.library.brown.edu/projects/crystalpalace/). Accessed May 14, 2020.

-   Galron-Goldshcläger, Joseph (Yossi). “Union List of Digitized Jewish Historic Newspapers, Periodicals, and e-Journals.” *Union List of Digitized Jewish Historic Newspapers, Periodicals, and e-Journals*, The Ohio State University, [*https://library.osu.edu/projects/hebrew-lexicon/Jewish-Press.htm*](https://library.osu.edu/projects/hebrew-lexicon/Jewish-Press.htm). Accessed May 14, 2020.

-   Kaganoff, Nathan M. *American Jewish History* 80, no. 1 (1990): 136-41. Accessed May 14, 2020. [*www.jstor.org/stable/23884484*](http://www.jstor.org/stable/23884484).

-   Nelson, David Ragnar, ed. “Digital Beehive.” *Digital Beehive*, Kislak Center for Special Collections, Rare Books, and Manuscripts, [*https://kislakcenter.github.io/digital-beehive/*](https://kislakcenter.github.io/digital-beehive/). Accessed May 14, 2020.]]></content><author><name>emily-esten</name></author><category term="Digital Second Edition of Judaica Americana" /><category term="Judaica Americana" /><category term="Digital Second Edition of Judaica Americana" /><category term="How Did They Make That" /><summary type="html"><![CDATA[As the project manager and developer for Judaica Digital Humanities at the Penn Libraries, I’m excited to announce the launch of the Digital Second Edition of Judaica Americana. This is an Omeka database which draws from Robert Singerman’s Judaica Americana, a bibliography chronicling American Jewish book production until 1900. The Digital Second Edition contains 3,000 supplemental entries to the print edition. The project’s features allow users to search the bibliography by author, language, holding institution, and various tags, as well as find open-access links to digitized Jewish monographs, serials, and periodicals.]]></summary></entry><entry><title type="html">Judaica Digital Humanities Launches the Digital Second Edition of Judaica Americana</title><link href="http://localhost:4000/blog/press-release-singermanja2/" rel="alternate" type="text/html" title="Judaica Digital Humanities Launches the Digital Second Edition of Judaica Americana" /><published>2020-06-30T00:00:00-04:00</published><updated>2020-06-30T00:00:00-04:00</updated><id>http://localhost:4000/blog/press-release-singermanja2</id><content type="html" xml:base="http://localhost:4000/blog/press-release-singermanja2/"><![CDATA[This press release has been republished with permission from [Penn Libraries](https://www.library.upenn.edu/blogs/libraries-news/judaica-digital-humanities-launches-digital-second-edition-judaica-americana). 

Judaica Digital Humanities at the Penn Libraries is excited to announce the launch of the [Digital Second Edition of Judaica Americana](https://singermanja2.exhibits.library.upenn.edu/). This bibliographic database draws from Robert Singerman’s *Judaica Americana*, the award-winning, magisterial two-volume bibliography of American Jewish publications before 1900. Visitors can search the database’s 9,600+ bibliographic entries by author, language, holding institution, and various tags, as well as find open-access links to digitized Jewish monographs, serials, and periodicals, when available.

Last October, Singerman donated to the Penn Libraries the draft of the full text and copyright to his revised second edition of *Judaica Americana*. Singerman’s first edition, issued in 1990 in two volumes, was sponsored by the Center for the Study of the American Jewish Experience, Hebrew Union College-Jewish Institute of Religion, and published by Greenwood Press as part of the Bibliographies and Indexes in American History. In the first edition, Singerman cataloged just over 6,500+ monographic and serial publications and presented each with meticulous bibliographical descriptions, classification explanations, and holdings information (i.e., the names of collections where copies are known to be held). 

*Judaica Americana* authoritatively chronicles American Jewish book production from the seventeenth century to the beginning of the twentieth century. The second edition contains an additional 3,000 entries. Taken as a whole, Singerman’s bibliography provides extensive documentation of American Jewish communal activity and growth before 1901.

Librarian Emeritus Singerman spent nearly three decades at the Price Library of Judaica at the University of Florida, where he grew an assortment of 24,000 unprocessed volumes to a fully-cataloged collection of over 85,000 volumes. For the second edition of *Judaica Americana*, the Association of Jewish Libraries awarded Singerman the 2020 Judaica Reference and Bibliography Lifetime Achievement Award. 

Singerman’s draft of the second edition — including a Supplements section, and two datasets based upon it — are now discoverable in [ScholarlyCommons](https://repository.upenn.edu/judaica_americana/), the University of Pennsylvania’s open access institutional repository. All the files now are available to researchers, book trade specialists, genealogists, and bibliographers with all information needed to mine this invaluable resource. 

Judaica Digital Humanities is profoundly grateful to Robert Singerman for entrusting his extraordinary work to the Penn Libraries.

*The project is an initiative of Judaica Digital Humanities at the Penn Libraries, which is a robust program of projects and tools for experimental digital scholarship with Judaica collections. Additional information about this project and program can be found on the [Judaica DH website](https://judaicadh.library.upenn.edu/work/judaica-americana/)*.]]></content><author><name>Penn Libraries</name></author><category term="Digital Second Edition of Judaica Americana" /><category term="Announcements" /><category term="Judaica Americana" /><category term="Digital Second Edition of Judaica Americana" /><summary type="html"><![CDATA[This press release has been republished with permission from Penn Libraries.]]></summary></entry><entry><title type="html">Resources for Learning More about the Cairo Geniza</title><link href="http://localhost:4000/blog/2020-05-15-resources-for-more/" rel="alternate" type="text/html" title="Resources for Learning More about the Cairo Geniza" /><published>2020-05-19T00:00:00-04:00</published><updated>2020-05-19T00:00:00-04:00</updated><id>http://localhost:4000/blog/2020-05-15-resources-for-more</id><content type="html" xml:base="http://localhost:4000/blog/2020-05-15-resources-for-more/"><![CDATA[### Resources for Learning More about the Cairo Geniza

![](https://cdn-images-1.medium.com/max/1440/1*Nq6_E3zrneGl_XXTbbnTfQ.jpeg)

Halper 142, University of Pennsylvania, Herbert D. Katz Center for Advanced Judaic Studies Library, Cairo Genizah Collection

One of the most frequently asked questions we get on the Scribes of the Cairo Geniza talk boards is learning more about the fragments and current research happening. Our priority is to share materials that are open-access to anyone. This list is **not** meant to be definitive, exhausting, or representative of all Geniza research! Feel free to email us at <judaicadh@gmail.com> with additional resources for this list. 

* * * * *

### Guides 

-   The [Jewish Virtual Library](https://www.jewishvirtuallibrary.org/genizah-cairo) provides an informative summary of the Cairo Geniza and survey of Geniza discoveries and research.
-   WNET New York Public Media put together [learning resources on the Cairo Geniza](https://whyy.pbslearningmedia.org/resource/sotj14.socst.world.cairogenizah/the-cairo-genizah/) to accompany Simon Schama's PBS series, *The Story of the Jews*.
-   This [guide from Johns Hopkins Sheridan Libraries](http://guides.library.jhu.edu/jewish-studies/genizah) provides a "Who's Who" in the history of Geniza collectors and scholars.

* * * * *

### **Articles**

-   [**Toolkit for Genizah Scholars: A Practical Guide for Neophytes**](https://hcommons.org/deposits/objects/hc:15904/datastreams/CONTENT/content)**,** compiled by Gregor Schwarb, includes introductory articles, websites, catalogues, and specific topics related to Cairo Geniza research. 
-   [**Finding a Fragment in a Pile of Geniza: A Practical Guide to Collections, Editions, and Resources**](https://www.academia.edu/38598025/Finding_a_Fragment_in_a_Pile_of_Geniza_A_Practical_Guide_to_Collections_Editions_and_Resources) by Oded Zinger complements the first toolkit by diving into the projects and editions that exist for Geniza scholars. 
-   [**"Some "Mass Produced" Scorpion-Amulets from the Cairo Genizah"**](https://books.google.com/books?id=5I8zfmwEjjUC&lpg=PP1&pg=PA35#v=onepage&q&f=false) by Gideon Bohak is my go-to introduction to amulets, which always capture volunteer attention. 
-   On a similar note,[**Geniza Magical Documents**](https://rd.springer.com/content/pdf/10.1007%2Fs10835-019-09322-6.pdf) by Ortal-Paz Saar introduces Geniza magical texts and provides some guidelines for reading these documents.
-   [**Fragment of the month**](https://www.lib.cam.ac.uk/collections/departments/taylor-schechter-genizah-research-unit/fragment-month) from the Taylor-Schechter Genizah Research Unit at Cambridge University Library is a series of blog posts from the unit's team as well as guest researchers that dive into unique fragments. 
-   For more on our project in particular, [**Of Scribes and Scripts: Citizen Science and the Cairo Geniza**](https://repository.upenn.edu/mss_sims/vol3/iss1/9) by the inaugural Judaica Digital Humanities Coordinator Laura Newman Eckstein provides a great summary of the framing of our project

* * * * *

### **Books** 

As a reminder, this list is **not** meant to be definitive, exhausting, or representative of all Geniza research! Rather, they address the topics that frequently come up from volunteers. 

(links to IndieBound or Google Books)

-   Gideon Bohak, [**Ancient Jewish Magic: A History**](https://books.google.co.il/books?id=DpJlOHceIjMC&lpg=PP1&dq=ancient%20jewish%20magic%20bohak&pg=PP1#v=onepage&q&f=false)
-   Edited by Gideon Bohak, Yuval Harari and Shaul Shaked, [**Continuity and Innovation in the Magical Tradition**](https://issuu.com/uomodellarinascita/docs/jsrc_015_bohak__harari__shaked__eds)
-   Jonathan Bloom, [**Paper before Print: The History and Impact of Paper in the Islamic World**](https://www.indiebound.org/book/9780300089554)
-   Patricia Crone, [**Pre-industrial Societies: Anatomy of the Pre-modern World**](https://www.indiebound.org/book/9781780747415)
-   S. D. Goitein, [**Letters of Medieval Jewish Traders**](https://www.indiebound.org/book/9780691618777)
-   S. D. Goitein, [**A Mediterranean Society** ](https://books.google.com/books/about/A_Mediterranean_Society.html?id=g13-owKVXY4C)
-   Amitav Ghosh, [**In an Antique Land**](https://www.indiebound.org/book/9781847081940)
-   Jessica Goldberg, [**Trade and Institutions in the Medieval Mediterranean**](https://www.indiebound.org/book/9781107519299)
-   Jessica Goldberg and Eve Krakowski, editors, [**Documentary Geniza Research in the Twenty-First Century**](https://link.springer.com/journal/10835/32/2)
-   Adina Hoffman and Peter Cole, [**Sacred Trash: The Lost and Found World of the Cairo Geniza**](https://www.indiebound.org/book/9780805212235)
-   Eve Krakowski, [**Coming of Age in Medieval Egypt: Female Adolescene, Jewish Law, and Ordinary Culture**](https://assets.press.princeton.edu/chapters/i11205.pdf)
-   This is a fictional novel, but Michael David Lukas's [**The Last Watchman of Old Cairo**](https://www.indiebound.org/book/9780399181160) often brings people to the project!
-   Stefan C. Reif, [**A Jewish Archive from Old Cairo: The History of Cambridge University's Genizah Collection**](https://www.indiebound.org/book/9780700712762) 
-   Marina Rustow, [**Heresy and the Politics of Community: The Jews of the Fatimid Caliphate**](https://www.indiebound.org/book/9780801456503)
-   Marina Rustow, [**The Lost Archive: Traces of a Caliphate in a Cairo Synagogue**](https://www.indiebound.org/book/9780691156477)
-   Solomon Schechter, "A Hoard of Hebrew Manuscripts," in his [**Studies in Judaism: Second Series **](https://archive.org/details/studiesinjuda00sche/page/n10/mode/2up)

* * * * *

### Scribes of the Cairo Geniza Project Team

#### Research Partners

-   [Judaica Digital Humanities at the Penn Libraries](https://judaicadh.github.io/)
-   [e-Lijah Lab at the University of Haifa](http://elijahlab.haifa.ac.il/index.php/en/about-eng)
-   [Princeton Geniza Lab](https://www.princeton.edu/~geniza/)
-   [Zooniverse](https://www.zooniverse.org/)

#### Image Partners

-   [Bodleian Libraries at the University of Oxford](https://www.bodleian.ox.ac.uk/bodley) ([digital library](https://genizah.bodleian.ox.ac.uk/))
-   [Taylor-Schecter Genizah Research Unit at Cambridge University Libraries](https://www.lib.cam.ac.uk/collections/departments/taylor-schechter-genizah-research-unit) ([digital library](https://cudl.lib.cam.ac.uk/collections/genizah/1))
-   [Columbia University Libraries](https://library.columbia.edu/) ([Hebrew manuscripts collection on Internet Archive](https://archive.org/details/culhebrewmss))
-   [National Library of Israel](https://web.nli.org.il/sites/nli/english/Pages/default.aspx) ([digital library](https://web.nli.org.il/sites/NLIS/en/ManuScript))
-   [Library of the Jewish Theological Seminary](http://www.jtsa.edu/library/) 
-   [The University of Manchester Library](https://www.library.manchester.ac.uk/) ([digital library](https://johannes.library.manchester.ac.uk/luna/servlet/ManchesterDev~95~2))
-   [University of Pennsylvania Libraries](https://www.library.upenn.edu/) ([digital library](http://openn.library.upenn.edu/html/genizah_contents.html))

* * * * *

### Resources from Judaica DH

[Cairo Geniza Alephbets](https://github.com/judaicadh/cairogeniza/tree/master/_docs/Eckstein%20Alephbet%20Chart) and the crib sheets viewable in the transcription workflow.

#### **Videos **

On our [YouTube channel](https://www.youtube.com/channel/UCxGa_DpdF02iF6Mbj5NB7ug), we have included a few playlist for your perusal.

-   [**Presentations**](https://www.youtube.com/playlist?list=PLnDafZMfagPYDPXp3G0vmAqrAIzTRTWxg)is a playlist featuringvarious presentations by our team about the project.
-   [**How-to**](https://www.youtube.com/playlist?list=PLnDafZMfagPbtgo8H817MwD7aNCy3ZQUf) is a playlist for getting started in the sorting and transcription workflows.
-   [**Resources about the Cairo Geniza**](https://www.youtube.com/playlist?list=PLnDafZMfagPaUOBoz29icEdmAnk-9NLH_)features lectures and videos from other institutions that may be of interest.

#### Blog

We periodically share conversations from the Talk boards in our Talking The Talk series or take a look at the data in our Data Deep Dives. Here are some of our most viewed posts about the project:

-   [10 Marriage Contracts from Penn's Cairo Geniza Collections](https://judaicadh.github.io/blog/2017-08-16-marriage-contracts/) 
-   [Birds of the Cairo Geniza](https://judaicadh.github.io/blog/2019-10-04-birds-cairo-geniza/)
-   [#MCN2019: Cultivating Community with the Cairo Geniza](https://judaicadh.github.io/blog/mcn-2019/)
-   [Reviewing the Sorting Phase: Overview](https://judaicadh.github.io/blog/sorting-phase-overview/)
-   [Scribes of the Seder](https://judaicadh.github.io/blog/2018-03-22-scribes-of-the-seder/)
-   [Taking a Closer Look: Arabic Script Calligraphy](https://judaicadh.github.io/blog/2019-03-15-arabic-script-calligraphy/)
-   [Talking the Talk: Chad Gad Yah](https://judaicadh.github.io/blog/2017-08-22-talking-the-talk/)
-   [The Story of Scripts and Keyboards](https://judaicadh.github.io/blog/2019-03-07-scripts-keyboards/)
-   [Who are the #GenizaScribes?](https://judaicadh.github.io/blog/2020-02-05-genizascribes/)

* * * * *

### Join us at [Scribes of the Cairo Geniza](https://www.scribesofthecairogeniza.org/) on Zooniverse!
 
As always, you can join us in classifying and transcribing fragments from the Cairo Geniza at [scribesofthecairogeniza.org](scribesofthecairogeniza.org). Note: This project is also available in Hebrew and Arabic. To switch, use the language toggle in the top right of the page.]]></content><author><name>admin</name></author><category term="Scribes of the Cairo Geniza" /><category term="Scribes of the Cairo Geniza" /><summary type="html"><![CDATA[Resources for Learning More about the Cairo Geniza]]></summary></entry></feed>